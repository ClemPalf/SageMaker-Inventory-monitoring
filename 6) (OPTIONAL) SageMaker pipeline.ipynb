{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) SageMaker pipeline\n",
    "In this notebook, we will create a sagemaker pipeline to automate the process of training a model, and updating the deployed endpoint if it perform better on a given test set.  \n",
    "Also slighty depricated, this documentation helped a lot:\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/define-pipeline.html  \n",
    "  \n",
    "All the scripts used by the different steps are available in the pipeline folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Bucket: sagemaker-us-east-1-646714458109\n",
      "AWS Region: us-east-1\n",
      "RoleArn: arn:aws:iam::646714458109:role/service-role/AmazonSageMaker-ExecutionRole-20211122T183493\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.tuner import CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics \n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "import json\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "\n",
    "session = sagemaker.Session()\n",
    "\n",
    "bucket = session.default_bucket()\n",
    "print(\"Default Bucket: {}\".format(bucket))\n",
    "\n",
    "region = session.boto_region_name\n",
    "print(\"AWS Region: {}\".format(region))\n",
    "\n",
    "role = get_execution_role()\n",
    "print(\"RoleArn: {}\".format(role))\n",
    "\n",
    "prefix = \"capstone-inventory-project\"\n",
    "model_package_group_name = \"Capstone_pipeline\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Define Pipeline Parameters\n",
    "\n",
    "training_instance_type – The ml.* instance type of the training jobs.\n",
    "\n",
    "input_data – The Amazon S3 location of the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=\"ml.g4dn.xlarge\"\n",
    ")\n",
    "\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=\"s3://{}/{}/data\".format(bucket, prefix)\n",
    ")\n",
    "\n",
    "# We will also define the were our model artefacts and evaluation results will be stored.\n",
    "model_path = \"s3://{}/{}/pipeline_model\".format(bucket, prefix)\n",
    "evaluation_file_path = \"s3://{}/{}/current_accuracy.json\".format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Training step\n",
    "First, let's create a training step.  \n",
    "This step will train a resnet34 for 5 epochs using the data in the specified folder.  \n",
    "Note that in this folder, is contained the inference script which will be moved alongside the model artefacts. This way, when instantiating a estimator, our inference script will be used by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch(\n",
    "    entry_point=\"pipeline/1_train_pipeline.py\",\n",
    "    role=role,\n",
    "    py_version='py36',\n",
    "    framework_version=\"1.8\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.g4dn.xlarge\",        \n",
    "    output_path = model_path,  # The training jobs output (mainly model artefacts) will go there.\n",
    "    hyperparameters={                                        \n",
    "        \"batch-size\": 64,\n",
    "        \"lr\": 0.01}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_train = TrainingStep(\n",
    "    name=\"Training\",\n",
    "    estimator=estimator,\n",
    "    inputs=input_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Evaluation step\n",
    "Next, a processing step was created to 1) load the model, 2) evaluate the model on the test set (acccuracy), and 3) save the result as a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"pytorch\",\n",
    "    region=region,\n",
    "    version=\"1.8\",\n",
    "    py_version=\"py36\",\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    image_scope=\"training\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_eval = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=\"pipeline-eval\",\n",
    "    role=role\n",
    "    #env= {\"MODEL_DATA\": step_train.properties.ModelArtifacts.S3ModelArtifacts}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\"\n",
    ")\n",
    "last_report = PropertyFile(\n",
    "    name=\"LastReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"current_accuracy.json\"\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"Evaluation\",\n",
    "    processor=script_eval,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=\"s3://sagemaker-us-east-1-646714458109/capstone-inventory-project/data/test/\",\n",
    "            destination=\"/opt/ml/processing/test\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=evaluation_file_path,\n",
    "            destination=\"/opt/ml/processing/accuracy\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "    ],\n",
    "    code=\"pipeline/2_evaluation.py\",\n",
    "    property_files=[evaluation_report, last_report]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Update endpoint\n",
    "\n",
    "If the newly trained model performed better than the model currently deployed (see step 4)), then the model endpoint will be udpdated.  \n",
    "Updating an endpoint permit to keep its name (which is usefull when others services like lambda functions rely on it) and ensure continuity of service.  \n",
    "The following processing function perform 2 main actions:\n",
    "- It updates the model with the new artefacts (by registering a model and an endpoint configuration).\n",
    "- It updates the current_accuracy.json file with the resuts obtained in the previous step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_update = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=\"update-endpoint\",\n",
    "    role=role,\n",
    "    env= {\"MODEL_DATA\": step_train.properties.ModelArtifacts.S3ModelArtifacts}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_update = ProcessingStep(\n",
    "    name=\"Update-endpoint\",\n",
    "    processor=script_update,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=\"{}/evaluation.json\".format(step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]),\n",
    "            destination=\"/opt/ml/processing/accuracy\"\n",
    "        )\n",
    "    ],\n",
    "    code=\"pipeline/3_update_endpoint.py\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Condition step\n",
    "In this step, we will compare the results obtained in step 2 to the S3 hosted \"current_accuracy.json\" file which contains the accuracy of the deployed model.  \n",
    "If the trained model has a greater accuracy, step 3 will start. Otherwise, nothing will happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False step\n",
    "script_else = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1,\n",
    "    base_job_name=\"else\",\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "step_fail = ProcessingStep(\n",
    "    name=\"Too-bad\",\n",
    "    processor=script_else,\n",
    "    code=\"pipeline/3_else.py\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_gte = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=\"Evaluation\",\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"accuracy\"\n",
    "    ),\n",
    "    right=JsonGet(\n",
    "        step_name=\"Evaluation\",\n",
    "        property_file=last_report,\n",
    "        json_path=\"accuracy\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_cond = ConditionStep(\n",
    "    name=\"Is-the-new_model-better-than-the-one-deployed\",\n",
    "    conditions=[cond_gte],\n",
    "    if_steps=[step_update],  # step_register\n",
    "    else_steps=[step_fail]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Pipeline creation\n",
    "Finally, all steps are concatenated to form a pipeline (it is import to give a role which has permissions for all the actions that will be performed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = \"CapstonePipeline\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        training_instance_type,\n",
    "        input_data\n",
    "    ],\n",
    "    steps=[step_train, step_eval, step_cond]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Version': '2020-12-01',\n",
       " 'Metadata': {},\n",
       " 'Parameters': [{'Name': 'TrainingInstanceType',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'ml.g4dn.xlarge'},\n",
       "  {'Name': 'InputData',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 's3://sagemaker-us-east-1-646714458109/capstone-inventory-project/data'}],\n",
       " 'PipelineExperimentConfig': {'ExperimentName': {'Get': 'Execution.PipelineName'},\n",
       "  'TrialName': {'Get': 'Execution.PipelineExecutionId'}},\n",
       " 'Steps': [{'Name': 'Training',\n",
       "   'Type': 'Training',\n",
       "   'Arguments': {'AlgorithmSpecification': {'TrainingInputMode': 'File',\n",
       "     'TrainingImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.8-gpu-py36',\n",
       "     'EnableSageMakerMetricsTimeSeries': True},\n",
       "    'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-646714458109/capstone-inventory-project/pipeline_model'},\n",
       "    'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       "    'ResourceConfig': {'InstanceCount': 1,\n",
       "     'InstanceType': 'ml.g4dn.xlarge',\n",
       "     'VolumeSizeInGB': 30},\n",
       "    'RoleArn': 'arn:aws:iam::646714458109:role/service-role/AmazonSageMaker-ExecutionRole-20211122T183493',\n",
       "    'InputDataConfig': [{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "        'S3Uri': {'Get': 'Parameters.InputData'},\n",
       "        'S3DataDistributionType': 'FullyReplicated'}},\n",
       "      'ChannelName': 'training'}],\n",
       "    'HyperParameters': {'batch-size': '64',\n",
       "     'lr': '0.01',\n",
       "     'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-646714458109/pytorch-training-2022-01-22-15-33-10-335/source/sourcedir.tar.gz\"',\n",
       "     'sagemaker_program': '\"1_train_pipeline.py\"',\n",
       "     'sagemaker_container_log_level': '20',\n",
       "     'sagemaker_job_name': '\"pytorch-training-2022-01-22-15-33-10-335\"',\n",
       "     'sagemaker_region': '\"us-east-1\"'},\n",
       "    'DebugHookConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-646714458109/capstone-inventory-project/pipeline_model',\n",
       "     'CollectionConfigurations': []},\n",
       "    'ProfilerRuleConfigurations': [{'RuleConfigurationName': 'ProfilerReport-1642865590',\n",
       "      'RuleEvaluatorImage': '503895931360.dkr.ecr.us-east-1.amazonaws.com/sagemaker-debugger-rules:latest',\n",
       "      'RuleParameters': {'rule_to_invoke': 'ProfilerReport'}}],\n",
       "    'ProfilerConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-646714458109/capstone-inventory-project/pipeline_model'}}},\n",
       "  {'Name': 'Evaluation',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': {'Get': 'Parameters.TrainingInstanceType'},\n",
       "      'InstanceCount': 1,\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.8-cpu-py36',\n",
       "     'ContainerEntrypoint': ['python3',\n",
       "      '/opt/ml/processing/input/code/2_evaluation.py']},\n",
       "    'RoleArn': 'arn:aws:iam::646714458109:role/service-role/AmazonSageMaker-ExecutionRole-20211122T183493',\n",
       "    'ProcessingInputs': [{'InputName': 'input-1',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': 'Steps.Training.ModelArtifacts.S3ModelArtifacts'},\n",
       "       'LocalPath': '/opt/ml/processing/model',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'input-2',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-646714458109/capstone-inventory-project/data/test/',\n",
       "       'LocalPath': '/opt/ml/processing/test',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'input-3',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-646714458109/capstone-inventory-project/current_accuracy.json',\n",
       "       'LocalPath': '/opt/ml/processing/accuracy',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-646714458109/pipeline-eval-2022-01-22-15-33-10-463/input/code/2_evaluation.py',\n",
       "       'LocalPath': '/opt/ml/processing/input/code',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}],\n",
       "    'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'evaluation',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-646714458109/pipeline-eval-2022-01-22-15-33-08-494/output/evaluation',\n",
       "        'LocalPath': '/opt/ml/processing/evaluation',\n",
       "        'S3UploadMode': 'EndOfJob'}}]}},\n",
       "   'PropertyFiles': [{'PropertyFileName': 'EvaluationReport',\n",
       "     'OutputName': 'evaluation',\n",
       "     'FilePath': 'evaluation.json'},\n",
       "    {'PropertyFileName': 'LastReport',\n",
       "     'OutputName': 'evaluation',\n",
       "     'FilePath': 'current_accuracy.json'}]},\n",
       "  {'Name': 'Is-the-new_model-better-than-the-one-deployed',\n",
       "   'Type': 'Condition',\n",
       "   'Arguments': {'Conditions': [{'Type': 'GreaterThanOrEqualTo',\n",
       "      'LeftValue': {'Std:JsonGet': {'PropertyFile': {'Get': 'Steps.Evaluation.PropertyFiles.EvaluationReport'},\n",
       "        'Path': 'accuracy'}},\n",
       "      'RightValue': {'Std:JsonGet': {'PropertyFile': {'Get': 'Steps.Evaluation.PropertyFiles.LastReport'},\n",
       "        'Path': 'accuracy'}}}],\n",
       "    'IfSteps': [{'Name': 'Update-endpoint',\n",
       "      'Type': 'Processing',\n",
       "      'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': {'Get': 'Parameters.TrainingInstanceType'},\n",
       "         'InstanceCount': 1,\n",
       "         'VolumeSizeInGB': 30}},\n",
       "       'AppSpecification': {'ImageUri': '763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.8-cpu-py36',\n",
       "        'ContainerEntrypoint': ['python3',\n",
       "         '/opt/ml/processing/input/code/3_update_endpoint.py']},\n",
       "       'RoleArn': 'arn:aws:iam::646714458109:role/service-role/AmazonSageMaker-ExecutionRole-20211122T183493',\n",
       "       'ProcessingInputs': [{'InputName': 'input-1',\n",
       "         'AppManaged': False,\n",
       "         'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-646714458109/pipeline-eval-2022-01-22-15-33-08-494/output/evaluation/evaluation.json',\n",
       "          'LocalPath': '/opt/ml/processing/accuracy',\n",
       "          'S3DataType': 'S3Prefix',\n",
       "          'S3InputMode': 'File',\n",
       "          'S3DataDistributionType': 'FullyReplicated',\n",
       "          'S3CompressionType': 'None'}},\n",
       "        {'InputName': 'code',\n",
       "         'AppManaged': False,\n",
       "         'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-646714458109/update-endpoint-2022-01-22-15-33-10-559/input/code/3_update_endpoint.py',\n",
       "          'LocalPath': '/opt/ml/processing/input/code',\n",
       "          'S3DataType': 'S3Prefix',\n",
       "          'S3InputMode': 'File',\n",
       "          'S3DataDistributionType': 'FullyReplicated',\n",
       "          'S3CompressionType': 'None'}}],\n",
       "       'Environment': {'MODEL_DATA': {'Get': 'Steps.Training.ModelArtifacts.S3ModelArtifacts'}}}}],\n",
       "    'ElseSteps': [{'Name': 'Too-bad',\n",
       "      'Type': 'Processing',\n",
       "      'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': 'ml.m5.large',\n",
       "         'InstanceCount': 1,\n",
       "         'VolumeSizeInGB': 30}},\n",
       "       'AppSpecification': {'ImageUri': '763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.8-cpu-py36',\n",
       "        'ContainerEntrypoint': ['python3',\n",
       "         '/opt/ml/processing/input/code/3_else.py']},\n",
       "       'RoleArn': 'arn:aws:iam::646714458109:role/service-role/AmazonSageMaker-ExecutionRole-20211122T183493',\n",
       "       'ProcessingInputs': [{'InputName': 'code',\n",
       "         'AppManaged': False,\n",
       "         'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-646714458109/else-2022-01-22-15-33-10-790/input/code/3_else.py',\n",
       "          'LocalPath': '/opt/ml/processing/input/code',\n",
       "          'S3DataType': 'S3Prefix',\n",
       "          'S3InputMode': 'File',\n",
       "          'S3DataDistributionType': 'FullyReplicated',\n",
       "          'S3CompressionType': 'None'}}]}}]}}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(pipeline.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:646714458109:pipeline/capstonepipeline',\n",
       " 'ResponseMetadata': {'RequestId': '0b068c3c-20db-427a-b172-c3cd325e2b00',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '0b068c3c-20db-427a-b172-c3cd325e2b00',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '84',\n",
       "   'date': 'Sat, 22 Jan 2022 15:33:12 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to test our pipeline!   \n",
    "Let's first re-deployed the model we trained in \"4) Model training resnet34.ipynb\" on a 5 instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and upload model\n",
    "pytorch_model = PyTorchModel(model_data=\"s3://sagemaker-us-east-1-646714458109/capstone-inventory-project/main_training/pytorch-training-2022-01-17-10-08-10-837/output/model.tar.gz\", \n",
    "                             role=role, \n",
    "                             entry_point=\"scripts/inference.py\",\n",
    "                             py_version='py3',\n",
    "                             framework_version='1.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "predictor = pytorch_model.deploy(initial_instance_count=1,\n",
    "                                 instance_type='ml.m5.large'\n",
    "                                )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pytorch-inference-2022-01-22-14-40-51-906'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a picture of the endpoint configuration settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/endpoint_start.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the pipeline was executed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "![alt text](images/pipeline_start.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"current-accuracy.json\" file was created with an initial value of 0.1, as the trained model reached 32% accuracy, the update-endpoint step was triggerded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/pipeline_success.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the following picture, our previous endpoint got his settings updated.  \n",
    "In addition to the new model artefacts, an elastic inference and data capture configurations were added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/endpoint_updated.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to executing the pipeline a second time, I manually deleted a few pictures from the training set.  \n",
    "Naturally, the trained model performed below 32% accucary and nothing happened."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/pipeline_fail.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a last sanity check (mainly to ensure that the endpoint is using the provided inference script), let's call our previously created lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('lambda')\n",
    "response = client.invoke(\n",
    "    FunctionName='inference_capstone',\n",
    "    Payload='{\"url\": \"https://sagemaker-us-east-1-646714458109.s3.amazonaws.com/capstone-inventory-project/data/train/1/00014.jpg\"}',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.024132639169692993,\n",
       "  0.014283359050750732,\n",
       "  -0.0014040172100067139,\n",
       "  -0.3216896057128906,\n",
       "  -0.8034760355949402]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response['Payload'].read().decode())[\"body\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is working fine!!"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
